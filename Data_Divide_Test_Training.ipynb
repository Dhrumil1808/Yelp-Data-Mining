{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Mining Project\n",
    "## CMPE - 255 Data Mining Fall 2017\n",
    "### Group 6\n",
    "- Dhrumil Shah\n",
    "- Nishant Rathi\n",
    "- Rashmi Sharma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to Preprocess Data and create CSR\n",
    "\n",
    "In this Jupyter Notebook, we are loading data from yelp data set sql dump. We have considered data using following constraints:\n",
    "- Users who have written 50 or more reviews\n",
    "- Their reviews\n",
    "- Rating of each of the review\n",
    "\n",
    "This data is grouped into 80% Training data and 20% Test data.\n",
    "We have grouped data by user ID and then split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_train_split_per_groupby(review_data,groupby, testperc):\n",
    "    uids=review_data[groupby].unique()\n",
    "    full_size = len(uids)\n",
    "    choose = (int)(((float)(testperc)/100) * full_size)\n",
    "    indices = np.random.choice(len(uids), choose, replace=False)\n",
    "    full_indices = [m for m in range(0,len(uids))]\n",
    "    train_indices = set(full_indices)-set(indices)\n",
    "    grouped =review_data.groupby([groupby])\n",
    "    test_indices_final=[]  \n",
    "    train_indices_final = []\n",
    "    for g in grouped.groups:\n",
    "        full_size = len(grouped.groups[g])\n",
    "        choose = (int)(((float)(testperc)/100) * full_size)\n",
    "        indices = np.random.choice(full_size, choose, replace=False)\n",
    "        full_indices = [m for m in range(0,full_size)]\n",
    "        train_indices = set(full_indices)-set(indices)\n",
    "        train_indices = list(train_indices)\n",
    "        test_indices_final.extend(list(grouped.groups[g][indices]))\n",
    "        train_indices_final.extend(list(grouped.groups[g][train_indices]))\n",
    "    \n",
    "    \n",
    "    saveGroupedData(\"data/test_\"+str(groupby)+\".dat\",test_indices_final)\n",
    "    saveGroupedData(\"data/train_\"+str(groupby)+\".dat\",train_indices_final)\n",
    "\n",
    "def saveGroupedData(filename, indices):\n",
    "    output_file = open(filename, 'w')\n",
    "    for i in indices:\n",
    "        output_file.write(str(i)+\"\\n\")\n",
    "    output_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data_all = pd.read_csv('dt.dat',\"\\t\")\n",
    "test_train_split_per_groupby(review_data_all,'UID',80)\n",
    "test_train_split_per_groupby(review_data_all,'BusinessId',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_data_all = pd.read_csv('data/reviews_with_counter.dat',\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking only 100K data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_data = review_data_all[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_train_split (review_data,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/reviews.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/test_temp.dat\", \"r\") as fh:\n",
    "    test_idx = fh.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/train_temp.dat\", \"r\") as fh:\n",
    "    train_idx = fh.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = open(\"data/train_final.dat\", 'w')\n",
    "for i in train_idx:\n",
    "    train_file.write(lines[int(i)-1])\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file = open(\"data/test_final.dat\", 'w')\n",
    "for i in test_idx:\n",
    "    test_file.write(lines[int(i)-1])\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
