{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import *\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import re\n",
    "import scipy as sp\n",
    "import seaborn\n",
    "import sklearn.feature_extraction.text as text\n",
    "\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines=[]\n",
    "with open(\"data/reviews_full.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userid = []\n",
    "rating = []\n",
    "docs = []\n",
    "business = []\n",
    "i = 0\n",
    "j = 0\n",
    "error_line_num = []\n",
    "error_lines = []\n",
    "for line in lines:\n",
    "    try:\n",
    "        i = i + 1\n",
    "        l = line.split('\\t', 4)\n",
    "        userid.append(l[0])\n",
    "        business.append(l[1])\n",
    "        rating.append(l[2])\n",
    "        docs.append(l[3])\n",
    "        #d = clean(l[3])\n",
    "        #kmers = getKmers(d)\n",
    "        #d.extend(kmers)\n",
    "        #docs.append(d)\n",
    "    except Exception as e:\n",
    "        j = j + 1\n",
    "        error_line_num.append(i)\n",
    "        error_lines.append(line)\n",
    "\n",
    "print 'Training Data: Number of lines processed: ' + str(i)\n",
    "print 'Training Data: Length of userid array: ' + str(len(userid))\n",
    "print 'Training Data: Length of rating array: ' + str(len(rating))\n",
    "print 'Training Data: Length of docs array: ' + str(len(docs))\n",
    "print 'Training Data: Length of business array: ' + str(len(business))\n",
    "print 'Training Data: Number of exceptions encountered: ' + str(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "n_samples = 50000\n",
    "n_features = 15000\n",
    "n_components = 30\n",
    "n_top_words = 50\n",
    "\n",
    "data_samples = docs[:n_samples]\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "\n",
    "tfidf_nmf = nmf.transform(tfidf)\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "#tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "vocab = np.array(tfidf_vectorizer.get_feature_names())\n",
    "#print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: Number of lines processed: 317586\n",
      "Training Data: Length of userid array: 317586\n",
      "Training Data: Length of rating array: 317586\n",
      "Training Data: Length of docs array: 317586\n",
      "Training Data: Length of business array: 317586\n",
      "Training Data: Number of exceptions encountered: 0\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import re\n",
    "import scipy as sp\n",
    "import seaborn\n",
    "import sklearn.feature_extraction.text as text\n",
    "\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import decomposition\n",
    "\n",
    "lines=[]\n",
    "with open(\"data/reviews_full.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines()  \n",
    "    \n",
    "userid = []\n",
    "rating = []\n",
    "docs = []\n",
    "business = []\n",
    "i = 0\n",
    "j = 0\n",
    "error_line_num = []\n",
    "error_lines = []\n",
    "for line in lines:\n",
    "    try:\n",
    "        i = i + 1\n",
    "        l = line.split('\\t', 4)\n",
    "        userid.append(l[0])\n",
    "        business.append(l[1])\n",
    "        rating.append(l[2])\n",
    "        docs.append(l[3])\n",
    "        #d = clean(l[3])\n",
    "        #kmers = getKmers(d)\n",
    "        #d.extend(kmers)\n",
    "        #docs.append(d)\n",
    "    except Exception as e:\n",
    "        j = j + 1\n",
    "        error_line_num.append(i)\n",
    "        error_lines.append(line)\n",
    "\n",
    "print 'Training Data: Number of lines processed: ' + str(i)\n",
    "print 'Training Data: Length of userid array: ' + str(len(userid))\n",
    "print 'Training Data: Length of rating array: ' + str(len(rating))\n",
    "print 'Training Data: Length of docs array: ' + str(len(docs))\n",
    "print 'Training Data: Length of business array: ' + str(len(business))\n",
    "print 'Training Data: Number of exceptions encountered: ' + str(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "total_data =50000\n",
    "train_data =40000\n",
    "\n",
    "def getSentiment(x):\n",
    "    if x < 3.0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "\n",
    "def nmf(rating):\n",
    "    nmf = load_pickle('nmf.pickle')\n",
    "    print nmf.shape\n",
    "    trainTopics= nmf[:total_data]\n",
    "    rating=rating[:total_data]\n",
    "    print trainTopics.shape\n",
    "    print len(rating)\n",
    "    trainTopics = trainTopics / np.sum(trainTopics, axis=1, keepdims=True)\n",
    "    d, f = trainTopics.shape\n",
    "    cols = [\"Topic\"+str(i) for i in xrange(1, f+1)]\n",
    "    nmfDF = pd.DataFrame(trainTopics, columns=cols)\n",
    "    nmfDF['rating'] = map(float,rating)\n",
    "    cols = [u'Topic1', u'Topic2', u'Topic3', u'Topic4', u'Topic5', u'Topic6', u'Topic7', u'Topic8', u'Topic9', u'Topic10', u'Topic11', u'Topic12', u'Topic13', u'Topic14', u'Topic15', u'Topic16', u'Topic17', u'Topic18', u'Topic19', u'Topic20']\n",
    "    Xtrain = nmfDF[:train_data][cols]\n",
    "    Ytrain = nmfDF[:train_data]['rating']\n",
    "    Xtest = nmfDF[train_data:][cols]\n",
    "    Ytest = nmfDF[train_data:]['rating']\n",
    "    \n",
    "    return nmfDF, Xtrain, Ytrain, Xtest, Ytest\n",
    "    \n",
    "    \n",
    "def nmf_sentiment(rating):\n",
    "    nmfDF,a,b,c,d = nmf(rating)\n",
    "    nmfDF['Sentiment'] = nmfDF['rating'].map(getSentiment)\n",
    "    nmfDF = nmfDF.dropna(how='any')\n",
    "    cols = [u'Topic1', u'Topic2', u'Topic3', u'Topic4', u'Topic5', u'Topic6', u'Topic7', u'Topic8', u'Topic9', u'Topic10', u'Topic11', u'Topic12', u'Topic13', u'Topic14', u'Topic15', u'Topic16', u'Topic17', u'Topic18', u'Topic19', u'Topic20', u'Sentiment']\n",
    "    Xtrain = nmfDF[:train_data][cols]\n",
    "    Ytrain = nmfDF[:train_data]['rating']\n",
    "    Xtest = nmfDF[train_data:][cols]\n",
    "    Ytest = nmfDF[train_data:]['rating']\n",
    "    \n",
    "    return nmfDF,Xtrain,Ytrain,Xtest,Ytest\n",
    "\n",
    "    \n",
    "    \n",
    "def lda_sentiment(rating):\n",
    "    lda = load_pickle('lda.pickle')\n",
    "    trainTopics= lda[:total_data]\n",
    "    rating=rating[:total_data]\n",
    "    trainTopics = trainTopics / np.sum(trainTopics, axis=1, keepdims=True)\n",
    "    d, f = trainTopics.shape\n",
    "    cols = [\"Topic\"+str(i) for i in xrange(1, f+1)]\n",
    "    ldaDF = pd.DataFrame(trainTopics, columns=cols)\n",
    "    ldaDF['rating'] = map(float,rating)\n",
    "    ldaDF['Sentiment'] = ldaDF['rating'].map(getSentiment)\n",
    "    ldaDF = ldaDF.dropna(how='any')\n",
    "    cols = [u'Topic1', u'Topic2', u'Topic3', u'Topic4', u'Topic5', u'Topic6', u'Topic7', u'Topic8', u'Topic9', u'Topic10', u'Topic11', u'Topic12', u'Topic13', u'Topic14', u'Topic15', u'Topic16', u'Topic17', u'Topic18', u'Topic19', u'Topic20', u'Sentiment']\n",
    "    Xtrain = ldaDF[:train_data][cols]\n",
    "    Ytrain = ldaDF[:train_data]['rating']\n",
    "    Xtest = ldaDF[train_data:][cols]\n",
    "    Ytest = ldaDF[train_data:]['rating']\n",
    "    \n",
    "    return ldaDF,Xtrain,Ytrain,Xtest,Ytest\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317586\n",
      "(50000, 20)\n",
      "(50000, 20)\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "rating = map(float,rating)\n",
    "print len(rating)\n",
    "df,train_X,train_Y,test_X,test_Y = nmf(rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 20)\n",
      "(50000, 20)\n",
      "50000\n",
      "(50000, 20)\n",
      "(50000, 20)\n",
      "50000\n",
      "Evalutaion of Model:  NMF\n",
      "********************************************************************\n",
      "Training validations evaluations for : Logistic Regression\n",
      "[ 0.45127436  0.45938515  0.45388653  0.45613597  0.45013747  0.43375\n",
      "  0.437       0.45047524  0.45472736  0.44947474]\n",
      "Testing validations evaluations for : Logistic Regression\n",
      "********************************************************************\n",
      "Training validations evaluations for : KNeighborsRegressor\n",
      "[ 0.04491631  0.0483624   0.00304631 -0.00614167  0.06293293  0.01400524\n",
      "  0.05819278  0.03223458  0.03774928 -0.01082228]\n",
      "Testing validations evaluations for : KNeighborsRegressor\n",
      "********************************************************************\n",
      "Training validations evaluations for : SVR\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "ModelEvaluationResults = {}\n",
    "\n",
    "rating = map(float,rating)\n",
    "\n",
    "models= [nmf(rating),nmf_sentiment(rating),lda_sentiment(rating)]\n",
    "model_names = [\"NMF\",\"NMF-Sentiment\",\"LDA-Sentiment\"]\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for (m,models_) in enumerate(models):\n",
    "    df,train_X,train_Y,test_X,test_Y = models_\n",
    "    print \"Evalutaion of Model:  \"+str(model_names[m])\n",
    "    \n",
    "    clfs = [ LogisticRegression(),\n",
    "    KNeighborsRegressor(n_neighbors=3),\n",
    "    SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    ]\n",
    "    #KernelRidge(alpha=1.0, coef0=1, degree=3, gamma=None, kernel='linear',kernel_params=None)]\n",
    "\n",
    "    #clf_names = ['Logistic Regression','KNeighborsRegressor','SVR','KernelRidge']\n",
    "    clf_names = ['Logistic Regression','KNeighborsRegressor','SVR']\n",
    "\n",
    "\n",
    "    \n",
    "    ClassifierEvaluationResults = {}\n",
    "    \n",
    "    for (i, clf_) in enumerate(clfs):\n",
    "        #clf = clf_.fit(Xtrain, Ytrain)\n",
    "        #preds = clf_.predict(Xtest)\n",
    "        print \"********************************************************************\"\n",
    "        print \"Training validations evaluations for : \"+str(clf_names[i])\n",
    "        scores = cross_val_score(clf_, train_X, train_Y, cv=10)\n",
    "        #predicted_ratings = cross_val_predict(clf_, test_X,test_Y, cv=10)\n",
    "        print scores\n",
    "        train_mean_score=scores.mean()\n",
    "        print \"Testing validations evaluations for : \"+str(clf_names[i])\n",
    "\n",
    "\n",
    "#         r2 = r2_score(test_Y, predicted_ratings, multioutput='uniform_average')\n",
    "#         mae = median_absolute_error(test_Y, predicted_ratings)\n",
    "#         msle =mean_squared_log_error(test_Y, predicted_ratings) \n",
    "#         mse = mean_squared_error(test_Y, predicted_ratings)\n",
    "#         mae = mean_absolute_error(test_Y, predicted_ratings)\n",
    "#         evs = explained_variance_score(test_Y, predicted_ratings)  \n",
    "        \n",
    "#         data ={'training score':train_mean_score,\n",
    "#             'r2 score':r2,\n",
    "#             'median absolute error':mae,\n",
    "#             'mean squared log error':msle,\n",
    "#             'mean sqaured error':mse,\n",
    "#             'mean absolute error':mae,\n",
    "#             'explained variance error':evs}\n",
    "\n",
    "        data ={'training_score':train_mean_score}        \n",
    "        \n",
    "        ClassifierEvaluationResults[clf_names[i]] = data\n",
    "        #print data\n",
    "    \n",
    "    ModelEvaluationResults[model_names[m]]=ClassifierEvaluationResults\n",
    "    print ClassifierEvaluationResults\n",
    "    print \"********************************************************************\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NMF': {'NMFSVR': {'r2 score': -0.20452192961501825, 'mean absolute error': 0.68470868630884918, 'mean sqaured error': 1.0720245173573664, 'training score': -0.19939618622008298, 'median absolute error': 0.68470868630884918, 'explained variance error': -0.19325356658519999, 'mean squared log error': 0.068210505250365788}, 'NMFLogistic Regression': {'r2 score': -0.011235955056179581, 'mean absolute error': 0.59999999999999998, 'mean sqaured error': 0.90000000000000002, 'training score': 0.37202380952380942, 'median absolute error': 0.59999999999999998, 'explained variance error': -2.2204460492503131e-16, 'mean squared log error': 0.060248331682490011}, 'NMFKNeighborsRegressor': {'r2 score': -0.24219725343320797, 'mean absolute error': 0.81666666666666665, 'mean sqaured error': 1.1055555555555554, 'training score': -0.81793112293368497, 'median absolute error': 0.81666666666666665, 'explained variance error': -0.20443196004993713, 'mean squared log error': 0.067274170527681892}}, 'LDA-Sentiment': {'LDA-SentimentLogistic Regression': {'r2 score': -0.011235955056179581, 'mean absolute error': 0.59999999999999998, 'mean sqaured error': 0.90000000000000002, 'training score': 0.40218253968253964, 'median absolute error': 0.59999999999999998, 'explained variance error': -2.2204460492503131e-16, 'mean squared log error': 0.060248331682490011}, 'LDA-SentimentSVR': {'r2 score': -0.1954930913063464, 'mean absolute error': 0.68925634871830277, 'mean sqaured error': 1.0639888512626485, 'training score': -0.039834539236726675, 'median absolute error': 0.68925634871830277, 'explained variance error': -0.18459802878108222, 'mean squared log error': 0.067881048716073394}, 'LDA-SentimentKNeighborsRegressor': {'r2 score': -0.67915106117353252, 'mean absolute error': 0.98333333333333339, 'mean sqaured error': 1.4944444444444442, 'training score': -0.019959811199449683, 'median absolute error': 0.98333333333333339, 'explained variance error': -0.62640449438202173, 'mean squared log error': 0.085804480583002579}}, 'NMF-Sentiment': {'NMF-SentimentLogistic Regression': {'r2 score': -0.011235955056179581, 'mean absolute error': 0.59999999999999998, 'mean sqaured error': 0.90000000000000002, 'training score': 0.37202380952380942, 'median absolute error': 0.59999999999999998, 'explained variance error': -2.2204460492503131e-16, 'mean squared log error': 0.060248331682490011}, 'NMF-SentimentKNeighborsRegressor': {'r2 score': -0.26092384519350764, 'mean absolute error': 0.83333333333333326, 'mean sqaured error': 1.1222222222222222, 'training score': -0.037050010522941282, 'median absolute error': 0.83333333333333326, 'explained variance error': -0.24968789013732828, 'mean squared log error': 0.067305966110579554}, 'NMF-SentimentSVR': {'r2 score': -0.20559687252451964, 'mean absolute error': 0.68458651240827595, 'mean sqaured error': 1.0729812165468227, 'training score': -0.027627565026825718, 'median absolute error': 0.68458651240827595, 'explained variance error': -0.1943468579800216, 'mean squared log error': 0.068262423304179504}}}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7e81b6a6947d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/rashmisharma/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                          copy=False)\n\u001b[1;32m    353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cols = ['training score', 'r2 score', 'median absolute error', 'mean squared log error','mean sqaured error','mean absolute error','explained variance error']\n",
    "#cols = ['training score', 'r2 score', 'median absolute error', 'mean squared log error','mean sqaured error','mean absolute error','explained variance error']\n",
    "clf_names = ['Logistic Regression','KNeighborsRegressor','SVR']\n",
    "model_names = [\"NMF\",\"NMF-Sentiment\",\"LDA-Sentiment\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print ModelEvaluationResults\n",
    "\n",
    "for m in model_names:\n",
    "    \n",
    "    print pd.DataFrame(m).T[clf_names].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
